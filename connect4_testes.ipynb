{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# -*- coding: utf-8 -*-\n\"\"\"Trabalho de IA.ipynb\n\nAutomatically generated by Colaboratory.\n\nOriginal file is located at\n    https://colab.research.google.com/drive/1CO8822b5WNj109EOK_bEi9Iz4ol7T5Fm\n\"\"\"\n\nimport numpy as np\nimport time\nfrom os import system, name\nimport random\n\nROWS = 12\nCOLUMNS = 13\n\nWINDOW_SIZE = 4  # Tamanho da janela que vai se mover pelo tabuleiro\nSTRIDE = 1  # Passo com o qual a janela vai se mover\n\nALPHA = -np.Inf\nBETA = np.Inf\nALPHA2= -np.Inf\nBETA2 = np.Inf\n\nSTATES_EXPLORED = 0\nSTATES_EXPLORED2 = 0\n\nTOTAL_AI_TIME = []\nTOTAL_AI_TIME2 = []\n\n\n# ----------------------------------------------------------------------------------\ndef clear():\n    # para windows\n    if name == 'nt':\n        _ = system('cls')\n\n    # para mac e linux(aqui, os.name eh 'posix')\n    else:\n        _ = system('clear')\n\n\n# ----------------------------------------------------------------------------------\ndef create_board():\n    board = np.zeros((ROWS, COLUMNS))\n    return board\n\n\n# ----------------------------------------------------------------------------------\ndef valid_location(board, column):\n    return board[0][column] == 0  # Tem que verificar a linha 0 e não a última\n\n\n# ----------------------------------------------------------------------------------\ndef drop_piece(board, column, piece):\n    for r in range(ROWS - 1, -1, -1):  # Troquei a ordem da lista, para começar de baixo\n        if board[r][column] == 0:\n            board[r][column] = piece\n            return\n\n\n# ----------------------------------------------------------------------------------\ndef is_winning_move(board, piece):\n    # verifica se existem quatro peças em linha na horizontal, vertical e diagonais\n    for c in range(COLUMNS - 3):\n        for r in range(ROWS):\n            if board[r][c] == piece and board[r][c + 1] == piece and board[r][c + 2] == piece and board[r][\n                c + 3] == piece:\n                return True\n    for c in range(COLUMNS):\n        for r in range(ROWS - 3):\n            if board[r][c] == piece and board[r + 1][c] == piece and board[r + 2][c] == piece and board[r + 3][\n                c] == piece:\n                return True\n    for c in range(COLUMNS - 3):\n        for r in range(ROWS - 3):\n            if board[r][c] == piece and board[r + 1][c + 1] == piece and board[r + 2][c + 2] == piece and board[r + 3][\n                c + 3] == piece:\n                return True\n    for c in range(COLUMNS - 3):\n        for r in range(3, ROWS):\n            if board[r][c] == piece and board[r - 1][c + 1] == piece and board[r - 2][c + 2] == piece and board[r - 3][\n                c + 3] == piece:\n                return True\n\n\ndef horizontal_score(window, piece, adversary, conditions):\n    score = 0\n\n    for r in range(WINDOW_SIZE):  # Verifica na horizontal a presença das peças\n        for cond, cond_score in conditions:\n            if np.count_nonzero(window[r, :] == piece) == cond[0] and np.count_nonzero(window[r, :] == 0) == cond[1]:\n                score += cond_score\n\n            if np.count_nonzero(window[r, :] == adversary) == cond[0] and \\\n                    np.count_nonzero(window[r, :] == 0) == cond[1]:\n                score -= cond_score\n\n    return score\n\n\ndef vertical_score(window, piece, adversary, conditions):\n    score = 0\n\n    for c in range(WINDOW_SIZE):  # Verifica na Vertical a presença das peças\n        for cond, cond_score in conditions:\n            if np.count_nonzero(window[:, c] == piece) == cond[0] and np.count_nonzero(window[:, c] == 0) == cond[1]:\n                score += cond_score\n\n            if np.count_nonzero(window[:, c] == adversary) == cond[0] and \\\n                    np.count_nonzero(window[:, c] == 0) == cond[1]:\n                score -= cond_score\n\n    return score\n\n\ndef diagonal_score(window, piece, adversary, conditions):\n    score = 0\n    diagonals = [window.diagonal(), np.fliplr(window).diagonal()]\n\n    for diagonal in diagonals:  # Verifica na Diagonal a presença das peças\n        for cond, cond_score in conditions:\n            if np.count_nonzero(diagonal == piece) == cond[0] and np.count_nonzero(diagonal == 0) == cond[1]:\n                score += cond_score\n            if np.count_nonzero(diagonal == adversary) == cond[0] and np.count_nonzero(diagonal == 0) == cond[1]:\n                score -= cond_score\n\n    return score\n\n\ndef window_score(window, piece):  # Baseado no conceito das sliding windows das CNNs\n    score = 0  # Vamos definir a pontuação de acordo com a quantidade de peças na janela\n    adversary = 1  # Por padrão o adversario será o jogador\n\n    conditions = [\n        ((4, 0), 100),\n        ((3, 1), 5),\n        ((2, 2), 2),\n        ((3, 1), - 4)\n    ]\n\n    if adversary == piece:\n        adversary = 2  # Caso a peça seja do jogador, setamos o adversario para a IA (2)\n\n    score += horizontal_score(window, piece, adversary, conditions)\n    score += vertical_score(window, piece, adversary, conditions)\n    score += diagonal_score(window, piece, adversary, conditions)\n\n    # print(f'Score: {score} ')\n    return score\n\n\ndef sliding_windows(board, piece):\n    score = 0\n\n    for c in range(0, COLUMNS - WINDOW_SIZE + 1, STRIDE):\n        for r in range(ROWS - WINDOW_SIZE, -1, -STRIDE):\n            window = board[r:r + WINDOW_SIZE, c:c + WINDOW_SIZE]\n            if np.count_nonzero(window[0, :] == 0) == WINDOW_SIZE:\n                break\n            score += window_score(window, piece)\n\n    return score\n\n\n# ----------------------------------------------------------------------------------\ndef minimax_alpha_beta2(board, depth, maximizing_player, alpha, beta, eval = False):\n    global STATES_EXPLORED2\n    global ALPHA2\n    global BETA2\n\n    if is_winning_move(board, 2):  # IA ganhou\n        return (None, 100)\n    elif is_winning_move(board, 1):  # jogador humano ganhou\n        return (None, -100)\n    elif len(get_valid_locations(board)) == 0:  # jogo empatado\n        return (None, 0)\n\n\n    elif depth == 0:  # profundidade máxima atingida\n        if eval == True:\n            return (None, sliding_windows(board, 2))\n        elif eval == False:\n            return (None, 0)  # Sem Heurística\n\n\n    valid_locations = get_valid_locations(board)\n\n    if maximizing_player:\n        value = -np.Inf\n        column = np.random.choice(valid_locations)\n        for col in valid_locations:\n            temp_board = board.copy()\n            drop_piece(temp_board, col, 2)\n\n            STATES_EXPLORED2 += 1\n\n            new_score = minimax_alpha_beta2(temp_board, depth - 1, False, ALPHA2, BETA2)[1]\n            if new_score > value:\n                value = new_score\n                column = col\n\n            ###############################################\n            ALPHA2 = max(ALPHA2, value)\n            if ALPHA2 >= BETA2:\n                break\n            ###############################################\n\n        return column, value\n\n    else:  # minimizing player\n        value = np.Inf\n        column = np.random.choice(valid_locations)\n        for col in valid_locations:\n            temp_board = board.copy()\n            drop_piece(temp_board, col, 1)\n\n            STATES_EXPLORED2 += 1\n\n            new_score = minimax_alpha_beta2(temp_board, depth - 1, True, ALPHA2, BETA2)[1]\n            if new_score < value:\n                value = new_score\n                column = col\n\n            ###############################################\n            BETA2 = min(BETA2, value)\n            if ALPHA2 >= BETA2:\n                break\n            ###############################################\n\n        return column, value\n\n\n# ----------------------------------------------------------------------------------\ndef minimax_alpha_beta(board, depth, maximizing_player, alpha, beta, eval = False):\n    global STATES_EXPLORED\n    global ALPHA\n    global BETA\n\n    if is_winning_move(board, 2):  # IA ganhou\n        return (None, 100)\n    elif is_winning_move(board, 1):  # jogador humano ganhou\n        return (None, -100)\n    elif len(get_valid_locations(board)) == 0:  # jogo empatado\n        return (None, 0)\n\n\n    # Heuristica\n    elif depth == 0:  # profundidade máxima atingida\n        if eval == True:\n            return (None, sliding_windows(board, 2))\n        elif eval == False:\n            return (None, 0)  # Sem Heurística\n\n\n    valid_locations = get_valid_locations(board)\n\n    if maximizing_player:\n        value = -np.Inf\n        column = np.random.choice(valid_locations)\n        for col in valid_locations:\n            temp_board = board.copy()\n            drop_piece(temp_board, col, 2)\n\n            STATES_EXPLORED += 1\n\n            new_score = minimax_alpha_beta(temp_board, depth - 1, False, ALPHA, BETA)[1]\n            if new_score > value:\n                value = new_score\n                column = col\n\n            ###############################################\n            ALPHA = max(ALPHA, value)\n            if ALPHA >= BETA:\n                break\n            ###############################################\n\n        return column, value\n\n    else:  # minimizing player\n        value = np.Inf\n        column = np.random.choice(valid_locations)\n        for col in valid_locations:\n            temp_board = board.copy()\n            drop_piece(temp_board, col, 1)\n\n            STATES_EXPLORED += 1\n\n            new_score = minimax_alpha_beta(temp_board, depth - 1, True, ALPHA, BETA)[1]\n            if new_score < value:\n                value = new_score\n                column = col\n\n            ###############################################\n            BETA = min(BETA, value)\n            if ALPHA >= BETA:\n                break\n            ###############################################\n\n        return column, value\n\n\n# -----------------------------------------------------------------------------------\ndef minimax_og2(board, depth, maximizing_player, eval = False):\n    global STATES_EXPLORED2\n\n    if is_winning_move(board, 2):  # IA ganhou\n        return (None, 100)\n    elif is_winning_move(board, 1):  # jogador humano ganhou\n        return (None, -100)\n    elif len(get_valid_locations(board)) == 0:  # jogo empatado\n        return (None, 0)\n\n        # Heuristica\n    elif depth == 0:  # profundidade máxima atingida\n        if eval == True:\n            return (None, sliding_windows(board, 2))\n        elif eval == False:\n            return (None, 0)  # Sem Heurística\n\n    valid_locations = get_valid_locations(board)\n\n    if maximizing_player:\n        value = -np.Inf\n        column = np.random.choice(valid_locations)\n        for col in valid_locations:\n            temp_board = board.copy()\n            drop_piece(temp_board, col, 2)\n            STATES_EXPLORED2 += 1\n            new_score = minimax_og2(temp_board, depth - 1, False)[1]\n            if new_score > value:\n                value = new_score\n                column = col\n        return column, value\n\n    else:  # minimizing player\n        value = np.Inf\n        column = np.random.choice(valid_locations)\n        for col in valid_locations:\n            temp_board = board.copy()\n            drop_piece(temp_board, col, 1)\n            STATES_EXPLORED2 += 1\n            new_score = minimax_og2(temp_board, depth - 1, True)[1]\n            if new_score < value:\n                value = new_score\n                column = col\n        return column, value\n\n\n# -----------------------------------------------------------------------------------\ndef minimax_og(board, depth, maximizing_player, eval = False):\n    global STATES_EXPLORED\n\n    if is_winning_move(board, 2):  # IA ganhou\n        return (None, 100)\n    elif is_winning_move(board, 1):  # jogador humano ganhou\n        return (None, -100)\n    elif len(get_valid_locations(board)) == 0:  # jogo empatado\n        return (None, 0)\n\n    # Heuristica\n    elif depth == 0:  # profundidade máxima atingida\n        if eval == True:\n            return (None, sliding_windows(board, 2))\n        elif eval == False:\n            return (None, 0)  # Sem Heurística\n\n    valid_locations = get_valid_locations(board)\n\n    if maximizing_player:\n        value = -np.Inf\n        column = np.random.choice(valid_locations)\n        for col in valid_locations:\n            temp_board = board.copy()\n            drop_piece(temp_board, col, 2)\n            STATES_EXPLORED += 1\n            new_score = minimax_og(temp_board, depth - 1, False)[1]\n            if new_score > value:\n                value = new_score\n                column = col\n        return column, value\n\n    else:  # minimizing player\n        value = np.Inf\n        column = np.random.choice(valid_locations)\n        for col in valid_locations:\n            temp_board = board.copy()\n            drop_piece(temp_board, col, 1)\n            STATES_EXPLORED += 1\n            new_score = minimax_og(temp_board, depth - 1, True)[1]\n            if new_score < value:\n                value = new_score\n                column = col\n        return column, value\n\n\n# ----------------------------------------------------------------------------------\ndef get_valid_locations(board):\n    valid_locations = []\n    for col in range(COLUMNS):\n        if valid_location(board, col):\n            valid_locations.append(col)\n    return valid_locations\n\n\n# ----------------------------------------------------------------------------------\n# CSI457 e CSI701\n# Programa Principal\n# Data: 06/05/2023\n# ----------------------------------------------------------------------------------\ndef test(var = 0, heur = False):\n    board = create_board()\n    game_over = False\n    turn = 0\n    first_play = True\n        \n    clear()\n    while not game_over:\n        # Movimento do Jogador 1\n        if turn == 0:\n            time_start = time.time()\n            \n            if var == 0:\n                col, minimax_score = minimax_og2(board, 4, False, heur)  # A profundidade máxima da árvore é 4\n            elif var== 1:\n                col, minimax_score = minimax_alpha_beta2(board, 4, False, ALPHA2, BETA2, heur)\n            \n            if(first_play):\n                col = random.randint(0,6)\n                # print(col)\n                first_play = False\n\n            try:\n                if valid_location(board, col):\n                    drop_piece(board, col, 1)\n                    if is_winning_move(board, 1):\n                        print(\"Jogador 1 Vence!!!\")\n                        game_over = True\n            except:\n                print(\"Empate !!!\")\n                game_over = True\n\n            time_end = time.time()\n            play_time = time_end - time_start\n            \n            '''print(f\"A jogada da IA demorou {play_time:.6f} segundos.\")\n            print(\"Estados explorados:\", STATES_EXPLORED2)'''\n            \n            \n            TOTAL_AI_TIME2.append(play_time)\n\n        # Movimento da IA\n        else:\n            time_start = time.time()\n            \n            if var == 0:\n                col, minimax_score = minimax_og(board, 4, True, heur)  # A profundidade máxima da árvore é 4\n            if var == 1:\n                col, minimax_score = minimax_alpha_beta(board, 4, True, ALPHA, BETA, heur)\n\n            if valid_location(board, col):\n                drop_piece(board, col, 2)\n                if is_winning_move(board, 2):\n                    print(\"Jogador 2 Vence!!!\")\n                    game_over = True\n                    \n            time_end = time.time()\n            play_time = time_end - time_start\n            \n            \n            \n            '''print(f\"A jogada da IA demorou {play_time:.6f} segundos.\")\n            print(\"Estados explorados:\", STATES_EXPLORED)'''\n            \n            TOTAL_AI_TIME.append(play_time)\n\n        '''print(board)\n        print(\" \")'''\n        turn += 1\n        turn = turn % 2\n    \n\n    \n    '''print(\"Estados explorados pelo jogador1:\", STATES_EXPLORED2)\n    print(\"Estados explorados pelo jogador2:\", STATES_EXPLORED)\n    print(f\"Tempo de jogo total do jogador1: {np.sum(TOTAL_AI_TIME2):.6f} segundos\")\n    print(f\"Tempo de jogo total da IA: {np.sum(TOTAL_AI_TIME):.6f} segundos\")'''\n    \n    return round(np.sum(TOTAL_AI_TIME2),6), round(np.sum(TOTAL_AI_TIME),6)\n    \ndef test_table(n, test, var = 0, heur = False):\n    global STATES_EXPLORED\n    global STATES_EXPLORED2\n    global TOTAL_AI_TIME2\n    global TOTAL_AI_TIME\n    \n    if var == 0:\n        print(\"Minimax\", end=\"\")\n    elif var == 1:\n        print(\"Minimax+Eval(s)\", end=\"\")\n    \n    if heur == 0:\n        print(\"\")\n    elif heur == 1:\n        print(\" + alfa-beta\")\n    \n    explored=[]\n    explored2=[]\n    total_time2=[]\n    total_time =[]\n    \n    for i in range(n):\n        c,d = test(var, heur)\n        explored.append(STATES_EXPLORED)\n        explored2.append(STATES_EXPLORED2)\n        total_time2.append(c)\n        total_time.append(d)\n        STATES_EXPLORED = 0\n        STATES_EXPLORED2 = 0\n        TOTAL_AI_TIME2 = []\n        TOTAL_AI_TIME = []\n    \n    print(\"Estados 1:\",explored)\n    print(\"Estados 2:\",explored2)\n    print(\"Tempo 1\",total_time2)\n    print(\"Tempo 2:\",total_time)","metadata":{"_uuid":"5eeff725-9be8-42e8-8709-dc2187c380a5","_cell_guid":"e1cc5f80-f2a2-4d63-b8c4-c202ee0929f8","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-07-13T05:08:50.007872Z","iopub.execute_input":"2023-07-13T05:08:50.008270Z","iopub.status.idle":"2023-07-13T05:08:50.068321Z","shell.execute_reply.started":"2023-07-13T05:08:50.008219Z","shell.execute_reply":"2023-07-13T05:08:50.067475Z"},"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"code","source":"n=5\n\ntest_table(n, test, var=0, heur=False)\nprint(\"\")\ntest_table(n, test, var=0, heur=True)\nprint(\"\")\ntest_table(n, test, var=1, heur=True)\nprint(\"\")\ntest_table(n, test, var=1, heur=False)","metadata":{"execution":{"iopub.status.busy":"2023-07-13T05:08:50.070330Z","iopub.execute_input":"2023-07-13T05:08:50.071092Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Minimax\n\u001b[H\u001b[2J","output_type":"stream"}]},{"cell_type":"markdown","source":"test_table(5, test, var=0, heur=True)","metadata":{"execution":{"iopub.status.busy":"2023-07-13T03:58:14.692546Z","iopub.execute_input":"2023-07-13T03:58:14.692834Z","iopub.status.idle":"2023-07-13T03:58:27.219750Z","shell.execute_reply.started":"2023-07-13T03:58:14.692809Z","shell.execute_reply":"2023-07-13T03:58:27.218629Z"}}},{"cell_type":"markdown","source":"test_table(5, test, var=1, heur=False)","metadata":{"execution":{"iopub.status.busy":"2023-07-13T03:58:27.306658Z","iopub.execute_input":"2023-07-13T03:58:27.306952Z","iopub.status.idle":"2023-07-13T03:58:27.392741Z","shell.execute_reply.started":"2023-07-13T03:58:27.306926Z","shell.execute_reply":"2023-07-13T03:58:27.391707Z"}}},{"cell_type":"markdown","source":"test_table(5, test, var=1, heur=True)","metadata":{"execution":{"iopub.status.busy":"2023-07-13T03:58:27.221021Z","iopub.execute_input":"2023-07-13T03:58:27.221339Z","iopub.status.idle":"2023-07-13T03:58:27.303704Z","shell.execute_reply.started":"2023-07-13T03:58:27.221311Z","shell.execute_reply":"2023-07-13T03:58:27.302494Z"}}}]}